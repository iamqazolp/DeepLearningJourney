{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d413b35c",
   "metadata": {},
   "source": [
    "2.1 Data Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f458dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f4f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.arange(12,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc441eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f890b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757281e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c1dfda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c27664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(size=(2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a6e59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,3,4),dtype=torch.int32)//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5401a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3515, -0.1185, -1.1081, -0.2519],\n",
       "         [ 0.0879,  2.0349, -0.2499, -0.4791],\n",
       "         [-1.8028, -0.5897,  0.6516, -0.2162]],\n",
       "\n",
       "        [[-0.9496,  0.9785,  0.7982, -0.2807],\n",
       "         [-0.9365, -0.7632, -0.0890,  1.9943],\n",
       "         [ 1.4480, -0.1267, -0.4041, -1.3240]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55893ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25, 26, 27, 28, 29])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor(list(range(0,30))).reshape(2,3,5)\n",
    "a[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa6583f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14]],\n",
       " \n",
       "         [[15, 16, 17, 18, 19],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29]]]),\n",
       " tensor([[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14],\n",
       "          [15, 16, 17, 18, 19],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29],\n",
       "          [30, 31, 32, 33, 34]],\n",
       " \n",
       "         [[35, 36, 37, 38, 39],\n",
       "          [40, 41, 42, 43, 44],\n",
       "          [45, 46, 47, 48, 49],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59],\n",
       "          [60, 61, 62, 63, 64],\n",
       "          [65, 66, 67, 68, 69]]]),\n",
       " tensor([[[ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14],\n",
       "          [ 0,  1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8,  9],\n",
       "          [10, 11, 12, 13, 14],\n",
       "          [15, 16, 17, 18, 19],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29],\n",
       "          [30, 31, 32, 33, 34]],\n",
       " \n",
       "         [[15, 16, 17, 18, 19],\n",
       "          [20, 21, 22, 23, 24],\n",
       "          [25, 26, 27, 28, 29],\n",
       "          [35, 36, 37, 38, 39],\n",
       "          [40, 41, 42, 43, 44],\n",
       "          [45, 46, 47, 48, 49],\n",
       "          [50, 51, 52, 53, 54],\n",
       "          [55, 56, 57, 58, 59],\n",
       "          [60, 61, 62, 63, 64],\n",
       "          [65, 66, 67, 68, 69]]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor(list(range(0,30))).reshape(2,3,5)\n",
    "b=torch.tensor(list(range(0,70))).reshape(2,7,5)\n",
    "c=torch.cat((a,b),dim=1)\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b1abe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.],\n",
       "          [ 2.],\n",
       "          [ 3.],\n",
       "          [ 4.],\n",
       "          [ 5.]],\n",
       " \n",
       "         [[ 6.],\n",
       "          [ 7.],\n",
       "          [ 8.],\n",
       "          [ 9.],\n",
       "          [10.]]]),\n",
       " tensor([1, 2, 3, 4]),\n",
       " tensor([[[ 2.,  3.,  4.,  5.],\n",
       "          [ 3.,  4.,  5.,  6.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 6.,  7.,  8.,  9.]],\n",
       " \n",
       "         [[ 7.,  8.,  9., 10.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [10., 11., 12., 13.],\n",
       "          [11., 12., 13., 14.]]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1, 11, dtype =torch.float32).reshape((2,5, 1))\n",
    "b = torch.arange(1, 5)\n",
    "a, b,a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaacb482",
   "metadata": {},
   "source": [
    "2.3 Linear Algrebras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30326f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_3648\\2205536390.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4416.)\n",
      "  torch.tensor(4.5458)*torch.arange(1,4).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5458,  9.0916, 13.6374])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(4.5458)*torch.arange(1,4).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a523c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=torch.arange(1,31,dtype=torch.float32).reshape(2,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e24e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.,  2.,  3.,  4.,  5.],\n",
       "          [ 6.,  7.,  8.,  9., 10.],\n",
       "          [11., 12., 13., 14., 15.]],\n",
       " \n",
       "         [[16., 17., 18., 19., 20.],\n",
       "          [21., 22., 23., 24., 25.],\n",
       "          [26., 27., 28., 29., 30.]]]),\n",
       " torch.Size([1, 3, 5]),\n",
       " tensor([[ 6.,  7.,  8.,  9., 10.],\n",
       "         [21., 22., 23., 24., 25.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A,A.sum(dim=0,keepdim=True).shape,A.mean(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00cab6e",
   "metadata": {},
   "source": [
    "2.4 Calculus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4091a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ad535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.30000\n",
      "2.03000\n",
      "2.00300\n",
      "2.00030\n",
      "2.00003\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 3*x**2-4*x\n",
    "for h in 10.0**np.arange(-1,-6,-1):\n",
    "    print(f\"{(f(1+h)-f(1))/h:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dae4613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib_inline import backend_inline\n",
    "def use_svg_display():  #@save\n",
    "    \"\"\"Use the svg format to display a plot in Jupyter.\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a29622",
   "metadata": {},
   "source": [
    "2.5 Automatic differentiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec226b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f76c52ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2bc27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=2*torch.dot(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc88156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5da0c902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5572f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=4*torch.dot(x,x)\n",
    "x.grad.zero_()\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9999215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  8., 16., 24.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7713b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(size=(2,1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c2ed963",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d22c0227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6093],\n",
       "        [-0.9439]], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f836e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.0000,  0.9999,  0.9998,  0.9997,  0.9995,  0.9993,  0.9990,\n",
       "         0.9987,  0.9984,  0.9980,  0.9976,  0.9972,  0.9967,  0.9961,  0.9956,\n",
       "         0.9949,  0.9943,  0.9936,  0.9929,  0.9921,  0.9913,  0.9904,  0.9896,\n",
       "         0.9886,  0.9877,  0.9867,  0.9856,  0.9845,  0.9834,  0.9823,  0.9811,\n",
       "         0.9798,  0.9785,  0.9772,  0.9759,  0.9745,  0.9730,  0.9716,  0.9701,\n",
       "         0.9685,  0.9669,  0.9653,  0.9637,  0.9620,  0.9602,  0.9584,  0.9566,\n",
       "         0.9548,  0.9529,  0.9510,  0.9490,  0.9470,  0.9450,  0.9429,  0.9408,\n",
       "         0.9386,  0.9364,  0.9342,  0.9319,  0.9296,  0.9273,  0.9249,  0.9225,\n",
       "         0.9201,  0.9176,  0.9151,  0.9125,  0.9099,  0.9073,  0.9046,  0.9019,\n",
       "         0.8992,  0.8964,  0.8936,  0.8908,  0.8879,  0.8850,  0.8821,  0.8791,\n",
       "         0.8761,  0.8730,  0.8699,  0.8668,  0.8637,  0.8605,  0.8572,  0.8540,\n",
       "         0.8507,  0.8474,  0.8440,  0.8406,  0.8372,  0.8338,  0.8303,  0.8267,\n",
       "         0.8232,  0.8196,  0.8160,  0.8123,  0.8086,  0.8049,  0.8012,  0.7974,\n",
       "         0.7936,  0.7898,  0.7859,  0.7820,  0.7780,  0.7741,  0.7701,  0.7660,\n",
       "         0.7620,  0.7579,  0.7538,  0.7496,  0.7455,  0.7412,  0.7370,  0.7327,\n",
       "         0.7285,  0.7241,  0.7198,  0.7154,  0.7110,  0.7066,  0.7021,  0.6976,\n",
       "         0.6931,  0.6885,  0.6840,  0.6793,  0.6747,  0.6701,  0.6654,  0.6607,\n",
       "         0.6559,  0.6512,  0.6464,  0.6416,  0.6367,  0.6319,  0.6270,  0.6221,\n",
       "         0.6171,  0.6122,  0.6072,  0.6022,  0.5972,  0.5921,  0.5870,  0.5819,\n",
       "         0.5768,  0.5716,  0.5665,  0.5613,  0.5561,  0.5508,  0.5456,  0.5403,\n",
       "         0.5350,  0.5297,  0.5243,  0.5189,  0.5136,  0.5081,  0.5027,  0.4973,\n",
       "         0.4918,  0.4863,  0.4808,  0.4753,  0.4697,  0.4642,  0.4586,  0.4530,\n",
       "         0.4474,  0.4418,  0.4361,  0.4304,  0.4248,  0.4191,  0.4133,  0.4076,\n",
       "         0.4018,  0.3961,  0.3903,  0.3845,  0.3787,  0.3729,  0.3670,  0.3612,\n",
       "         0.3553,  0.3494,  0.3435,  0.3376,  0.3317,  0.3257,  0.3198,  0.3138,\n",
       "         0.3078,  0.3018,  0.2958,  0.2898,  0.2838,  0.2778,  0.2717,  0.2656,\n",
       "         0.2596,  0.2535,  0.2474,  0.2413,  0.2352,  0.2291,  0.2230,  0.2168,\n",
       "         0.2107,  0.2045,  0.1984,  0.1922,  0.1860,  0.1798,  0.1736,  0.1675,\n",
       "         0.1612,  0.1550,  0.1488,  0.1426,  0.1364,  0.1301,  0.1239,  0.1177,\n",
       "         0.1114,  0.1052,  0.0989,  0.0926,  0.0864,  0.0801,  0.0738,  0.0676,\n",
       "         0.0613,  0.0550,  0.0487,  0.0424,  0.0362,  0.0299,  0.0236,  0.0173,\n",
       "         0.0110,  0.0047, -0.0016, -0.0079, -0.0142, -0.0204, -0.0267, -0.0330,\n",
       "        -0.0393, -0.0456, -0.0519, -0.0581, -0.0644, -0.0707, -0.0770, -0.0832,\n",
       "        -0.0895, -0.0958, -0.1020, -0.1083, -0.1145, -0.1208, -0.1270, -0.1333,\n",
       "        -0.1395, -0.1457, -0.1519, -0.1581, -0.1643, -0.1706, -0.1767, -0.1829,\n",
       "        -0.1891, -0.1953, -0.2014, -0.2076, -0.2138, -0.2199, -0.2260, -0.2321,\n",
       "        -0.2383, -0.2444, -0.2505, -0.2565, -0.2626, -0.2687, -0.2747, -0.2808,\n",
       "        -0.2868, -0.2928, -0.2988, -0.3048, -0.3108, -0.3168, -0.3227, -0.3287,\n",
       "        -0.3346, -0.3405, -0.3464, -0.3523, -0.3582, -0.3641, -0.3699, -0.3758,\n",
       "        -0.3816, -0.3874, -0.3932, -0.3990, -0.4047, -0.4105, -0.4162, -0.4219,\n",
       "        -0.4276, -0.4333, -0.4389, -0.4446, -0.4502, -0.4558, -0.4614, -0.4670,\n",
       "        -0.4725, -0.4781, -0.4836, -0.4891, -0.4945, -0.5000, -0.5054, -0.5109,\n",
       "        -0.5163, -0.5216, -0.5270, -0.5323, -0.5376, -0.5429, -0.5482, -0.5534,\n",
       "        -0.5587, -0.5639, -0.5691, -0.5742, -0.5794, -0.5845, -0.5896, -0.5946,\n",
       "        -0.5997, -0.6047, -0.6097, -0.6147, -0.6196, -0.6245, -0.6294, -0.6343,\n",
       "        -0.6392, -0.6440, -0.6488, -0.6536, -0.6583, -0.6630, -0.6677, -0.6724,\n",
       "        -0.6770, -0.6817, -0.6862, -0.6908, -0.6953, -0.6998, -0.7043, -0.7088,\n",
       "        -0.7132, -0.7176, -0.7220, -0.7263, -0.7306, -0.7349, -0.7391, -0.7434,\n",
       "        -0.7475, -0.7517, -0.7558, -0.7599, -0.7640, -0.7681, -0.7721, -0.7761,\n",
       "        -0.7800, -0.7839, -0.7878, -0.7917, -0.7955, -0.7993, -0.8031, -0.8068,\n",
       "        -0.8105, -0.8142, -0.8178, -0.8214, -0.8250, -0.8285, -0.8320, -0.8355,\n",
       "        -0.8389, -0.8423, -0.8457, -0.8490, -0.8524, -0.8556, -0.8589, -0.8621,\n",
       "        -0.8652, -0.8684, -0.8715, -0.8745, -0.8776, -0.8806, -0.8835, -0.8865,\n",
       "        -0.8894, -0.8922, -0.8950, -0.8978, -0.9006, -0.9033, -0.9060, -0.9086,\n",
       "        -0.9112, -0.9138, -0.9163, -0.9188, -0.9213, -0.9237, -0.9261, -0.9285,\n",
       "        -0.9308, -0.9331, -0.9353, -0.9375, -0.9397, -0.9418, -0.9439, -0.9460,\n",
       "        -0.9480, -0.9500, -0.9519, -0.9538, -0.9557, -0.9575, -0.9593, -0.9611,\n",
       "        -0.9628, -0.9645, -0.9661, -0.9677, -0.9693, -0.9708, -0.9723, -0.9738,\n",
       "        -0.9752, -0.9766, -0.9779, -0.9792, -0.9804, -0.9817, -0.9828, -0.9840,\n",
       "        -0.9851, -0.9861, -0.9872, -0.9882, -0.9891, -0.9900, -0.9909, -0.9917,\n",
       "        -0.9925, -0.9932, -0.9939, -0.9946, -0.9953, -0.9958, -0.9964, -0.9969,\n",
       "        -0.9974, -0.9978, -0.9982, -0.9986, -0.9989, -0.9992, -0.9994, -0.9996,\n",
       "        -0.9998, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -0.9998,\n",
       "        -0.9996, -0.9994, -0.9992, -0.9989, -0.9986, -0.9982, -0.9978, -0.9974,\n",
       "        -0.9969, -0.9964, -0.9958, -0.9953, -0.9946, -0.9939, -0.9932, -0.9925,\n",
       "        -0.9917, -0.9909, -0.9900, -0.9891, -0.9882, -0.9872, -0.9861, -0.9851,\n",
       "        -0.9840, -0.9828, -0.9817, -0.9804, -0.9792, -0.9779, -0.9766, -0.9752,\n",
       "        -0.9738, -0.9723, -0.9708, -0.9693, -0.9677, -0.9661, -0.9645, -0.9628,\n",
       "        -0.9611, -0.9593, -0.9575, -0.9557, -0.9538, -0.9519, -0.9500, -0.9480,\n",
       "        -0.9460, -0.9439, -0.9418, -0.9397, -0.9375, -0.9353, -0.9331, -0.9308,\n",
       "        -0.9285, -0.9261, -0.9237, -0.9213, -0.9188, -0.9163, -0.9138, -0.9112,\n",
       "        -0.9086, -0.9060, -0.9033, -0.9006, -0.8978, -0.8950, -0.8922, -0.8894,\n",
       "        -0.8865, -0.8835, -0.8806, -0.8776, -0.8745, -0.8715, -0.8684, -0.8652,\n",
       "        -0.8621, -0.8589, -0.8556, -0.8524, -0.8490, -0.8457, -0.8423, -0.8389,\n",
       "        -0.8355, -0.8320, -0.8285, -0.8250, -0.8214, -0.8178, -0.8142, -0.8105,\n",
       "        -0.8068, -0.8031, -0.7993, -0.7955, -0.7917, -0.7878, -0.7839, -0.7800,\n",
       "        -0.7761, -0.7721, -0.7681, -0.7640, -0.7599, -0.7558, -0.7517, -0.7475,\n",
       "        -0.7434, -0.7391, -0.7349, -0.7306, -0.7263, -0.7220, -0.7176, -0.7132,\n",
       "        -0.7088, -0.7043, -0.6998, -0.6953, -0.6908, -0.6862, -0.6817, -0.6770,\n",
       "        -0.6724, -0.6677, -0.6630, -0.6583, -0.6536, -0.6488, -0.6440, -0.6392,\n",
       "        -0.6343, -0.6294, -0.6245, -0.6196, -0.6147, -0.6097, -0.6047, -0.5997,\n",
       "        -0.5946, -0.5896, -0.5845, -0.5794, -0.5742, -0.5691, -0.5639, -0.5587,\n",
       "        -0.5534, -0.5482, -0.5429, -0.5376, -0.5323, -0.5270, -0.5216, -0.5163,\n",
       "        -0.5109, -0.5054, -0.5000, -0.4945, -0.4891, -0.4836, -0.4781, -0.4725,\n",
       "        -0.4670, -0.4614, -0.4558, -0.4502, -0.4446, -0.4389, -0.4333, -0.4276,\n",
       "        -0.4219, -0.4162, -0.4105, -0.4047, -0.3990, -0.3932, -0.3874, -0.3816,\n",
       "        -0.3758, -0.3699, -0.3641, -0.3582, -0.3523, -0.3464, -0.3405, -0.3346,\n",
       "        -0.3287, -0.3227, -0.3168, -0.3108, -0.3048, -0.2988, -0.2928, -0.2868,\n",
       "        -0.2808, -0.2747, -0.2687, -0.2626, -0.2565, -0.2505, -0.2444, -0.2383,\n",
       "        -0.2321, -0.2260, -0.2199, -0.2138, -0.2076, -0.2014, -0.1953, -0.1891,\n",
       "        -0.1829, -0.1767, -0.1706, -0.1643, -0.1581, -0.1519, -0.1457, -0.1395,\n",
       "        -0.1333, -0.1270, -0.1208, -0.1145, -0.1083, -0.1020, -0.0958, -0.0895,\n",
       "        -0.0832, -0.0770, -0.0707, -0.0644, -0.0581, -0.0519, -0.0456, -0.0393,\n",
       "        -0.0330, -0.0267, -0.0204, -0.0142, -0.0079, -0.0016,  0.0047,  0.0110,\n",
       "         0.0173,  0.0236,  0.0299,  0.0362,  0.0424,  0.0487,  0.0550,  0.0613,\n",
       "         0.0676,  0.0738,  0.0801,  0.0864,  0.0926,  0.0989,  0.1052,  0.1114,\n",
       "         0.1177,  0.1239,  0.1301,  0.1364,  0.1426,  0.1488,  0.1550,  0.1612,\n",
       "         0.1675,  0.1736,  0.1798,  0.1860,  0.1922,  0.1984,  0.2045,  0.2107,\n",
       "         0.2168,  0.2230,  0.2291,  0.2352,  0.2413,  0.2474,  0.2535,  0.2596,\n",
       "         0.2656,  0.2717,  0.2778,  0.2838,  0.2898,  0.2958,  0.3018,  0.3078,\n",
       "         0.3138,  0.3198,  0.3257,  0.3317,  0.3376,  0.3435,  0.3494,  0.3553,\n",
       "         0.3612,  0.3670,  0.3729,  0.3787,  0.3845,  0.3903,  0.3961,  0.4018,\n",
       "         0.4076,  0.4133,  0.4191,  0.4248,  0.4304,  0.4361,  0.4418,  0.4474,\n",
       "         0.4530,  0.4586,  0.4642,  0.4697,  0.4753,  0.4808,  0.4863,  0.4918,\n",
       "         0.4973,  0.5027,  0.5081,  0.5136,  0.5189,  0.5243,  0.5297,  0.5350,\n",
       "         0.5403,  0.5456,  0.5508,  0.5561,  0.5613,  0.5665,  0.5716,  0.5768,\n",
       "         0.5819,  0.5870,  0.5921,  0.5972,  0.6022,  0.6072,  0.6122,  0.6171,\n",
       "         0.6221,  0.6270,  0.6319,  0.6367,  0.6416,  0.6464,  0.6512,  0.6559,\n",
       "         0.6607,  0.6654,  0.6701,  0.6747,  0.6793,  0.6840,  0.6885,  0.6931,\n",
       "         0.6976,  0.7021,  0.7066,  0.7110,  0.7154,  0.7198,  0.7241,  0.7285,\n",
       "         0.7327,  0.7370,  0.7412,  0.7455,  0.7496,  0.7538,  0.7579,  0.7620,\n",
       "         0.7660,  0.7701,  0.7741,  0.7780,  0.7820,  0.7859,  0.7897,  0.7936,\n",
       "         0.7974,  0.8012,  0.8049,  0.8086,  0.8123,  0.8160,  0.8196,  0.8232,\n",
       "         0.8267,  0.8303,  0.8338,  0.8372,  0.8406,  0.8440,  0.8474,  0.8507,\n",
       "         0.8540,  0.8572,  0.8605,  0.8637,  0.8668,  0.8699,  0.8730,  0.8761,\n",
       "         0.8791,  0.8821,  0.8850,  0.8879,  0.8908,  0.8936,  0.8964,  0.8992,\n",
       "         0.9019,  0.9046,  0.9073,  0.9099,  0.9125,  0.9151,  0.9176,  0.9201,\n",
       "         0.9225,  0.9249,  0.9273,  0.9296,  0.9319,  0.9342,  0.9364,  0.9386,\n",
       "         0.9408,  0.9429,  0.9450,  0.9470,  0.9490,  0.9510,  0.9529,  0.9548,\n",
       "         0.9566,  0.9584,  0.9602,  0.9620,  0.9637,  0.9653,  0.9669,  0.9685,\n",
       "         0.9701,  0.9716,  0.9730,  0.9745,  0.9759,  0.9772,  0.9785,  0.9798,\n",
       "         0.9811,  0.9823,  0.9834,  0.9845,  0.9856,  0.9867,  0.9877,  0.9886,\n",
       "         0.9896,  0.9904,  0.9913,  0.9921,  0.9929,  0.9936,  0.9943,  0.9949,\n",
       "         0.9956,  0.9961,  0.9967,  0.9972,  0.9976,  0.9980,  0.9984,  0.9987,\n",
       "         0.9990,  0.9993,  0.9995,  0.9997,  0.9998,  0.9999,  1.0000,  1.0000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create x with requires_grad=True\n",
    "x = torch.linspace(0, 2 * torch.pi, 1000, requires_grad=True)\n",
    "\n",
    "# Define the function\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Reduce y to a scalar to call backward\n",
    "y.sum().backward()\n",
    "y.sum()\n",
    "# x.grad now contains the derivative (dy/dx) for each x\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5568410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.1041e-06, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5683c1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(62.), tensor([[ 9., 12., 12.,  6.,  5.,  1.,  9.,  1.,  7.]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.randint(1,15,size=(1,9),dtype=torch.float32)\n",
    "t.sum(),t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9b8ac32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.7065)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4337deb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(134.8889)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.ones_like(t)*t.sum()/t.numel()\n",
    "(t-b).norm()**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19fcf751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(134.8898)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t-b-0.01).norm()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65d2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
